{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TRi3zEJ5Vkj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQgwNUoV3Kln"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNMV9jQt4wNA"
      },
      "outputs": [],
      "source": [
        "img_path = \"/content/drive/MyDrive/UGP_EE492A/PSO_results/images/4.jpg\"\n",
        "img = cv.imread(\"/content/drive/MyDrive/UGP_EE492A/PSO_results/images/4.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cf5G_CMNc-T"
      },
      "outputs": [],
      "source": [
        "img.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsVZ4zra3_bQ"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nD-u-p459Ok"
      },
      "outputs": [],
      "source": [
        "def color_hist(img):\n",
        "\n",
        "    y = np.linspace(0 ,256)\n",
        "    fig , ax = plt.subplots(3,1)\n",
        "    ax[0].hist(img[:,:,0].flatten().ravel(),color='blue',bins = 1846)\n",
        "    ax[1].hist(img[:,:,1].flatten().ravel(),color='green',bins = 1846)\n",
        "    ax[2].hist(img[:,:,2].flatten().ravel(),color='red',bins = 1846)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLtU6gqF69VD"
      },
      "outputs": [],
      "source": [
        "def plot_hist(img):\n",
        "\n",
        "    plt.hist(img.flatten(),bins = 1846)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk6sKHOMJ8lK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def suggest_bin_value_for_color_hist(channel):\n",
        "    total_pixels = np.prod(channel.shape)\n",
        "    # print(total_pixels)\n",
        "    suggested_bins = int(np.sqrt(total_pixels))\n",
        "    return suggested_bins\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw3HR-iDKBVG"
      },
      "outputs": [],
      "source": [
        "suggest_bin_value_for_color_hist(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp-j3BSM7SnC"
      },
      "outputs": [],
      "source": [
        "def image(input):\n",
        "    val = list(input)\n",
        "\n",
        "    for p in range(len(val)):\n",
        "        if val[p][1]==\"B\":\n",
        "            b = val[p][0]\n",
        "        elif val[p][1]==\"G\":\n",
        "            g = val[p][0]\n",
        "        if val[p][1]==\"R\":\n",
        "            r = val[p][0]\n",
        "\n",
        "    img = np.dstack([b,g,r])\n",
        "    img = np.array(img,dtype=np.uint8)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-Sry_7i7UKS"
      },
      "outputs": [],
      "source": [
        "# Indicating superior, inferior and intermediate channels based on mean of pixels in channel\n",
        "def superior_inferior_split(img):\n",
        "\n",
        "    B, G, R = cv.split(img)\n",
        "\n",
        "    pixel = {\"B\":np.mean(B) ,\"G\":np.mean(G),\"R\":np.mean(R)}\n",
        "    # print(\"Pixel \", pixel)\n",
        "    pixel_ordered = dict(sorted(pixel.items(), key=lambda x: x[1], reverse=True))\n",
        "    # print(\"pixel_ordered \", pixel_ordered)\n",
        "\n",
        "    # Classifying Maximum, Minimum and Intermediate channels of image\n",
        "    label =[\"Pmax\",\"Pint\",\"Pmin\"]\n",
        "    chanel={}\n",
        "\n",
        "    for i,j in zip(range(len(label)),pixel_ordered.keys()):\n",
        "         if j==\"B\":\n",
        "             chanel[label[i]]=list([B,j])\n",
        "\n",
        "         elif j==\"G\":\n",
        "             chanel[label[i]]=list([G,j])\n",
        "\n",
        "         else:\n",
        "             chanel[label[i]]=list([R,j])\n",
        "    return chanel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S2w9aPV7WKK"
      },
      "outputs": [],
      "source": [
        "def neutralize_image(img):\n",
        "\n",
        "    track = superior_inferior_split(img)\n",
        "\n",
        "    Pmax = track[\"Pmax\"][0]\n",
        "    Pint = track[\"Pint\"][0]\n",
        "    Pmin = track[\"Pmin\"][0]\n",
        "\n",
        "    #gain_factor Pint\n",
        "    J = (np.sum(Pmax) - np.sum(Pint))/(np.sum(Pmax) + np.sum(Pint))\n",
        "\n",
        "    #gain_factor Pmin\n",
        "    K = (np.sum(Pmax) - np.sum(Pmin))/(np.sum(Pmax) + np.sum(Pmin))\n",
        "\n",
        "    for i in range(len(track[\"Pint\"][0])):\n",
        "        for j in range(len(track[\"Pint\"][0][i])):\n",
        "            if track[\"Pint\"][0][i][j] < 200:\n",
        "                track[\"Pint\"][0][i][j] += J * Pmax[i][j]\n",
        "\n",
        "    for i in range(len(track[\"Pmin\"][0])):\n",
        "        for j in range(len(track[\"Pmin\"][0][i])):\n",
        "            if track[\"Pmin\"][0][i][j] < 200:\n",
        "                track[\"Pmin\"][0][i][j] += J * Pmax[i][j]\n",
        "\n",
        "    #neutralised image\n",
        "    neu_img = image(track.values())\n",
        "\n",
        "    return neu_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUmZa6st722L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def Stretching(image, trim_percent=10):\n",
        "    LSR_img = []  # for lower stretched image\n",
        "    USR_img = []  # for upper stretched image\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    for i in range(image.shape[2]):\n",
        "        img_hist = image[:,:,i]\n",
        "        max_P = np.max(img_hist)\n",
        "        min_P = np.min(img_hist)\n",
        "\n",
        "        # Calculate trimmed mean\n",
        "        trimmed_mean = np.mean(np.sort(img_hist.flatten())[int(trim_percent/2):-int(trim_percent/2)])\n",
        "\n",
        "        median_P = np.median(img_hist)\n",
        "        avg_point = (trimmed_mean + median_P) / 2\n",
        "\n",
        "        LS_img = np.zeros((height, width))\n",
        "        US_img = np.zeros((height, width))\n",
        "\n",
        "        for i in range(0, height):\n",
        "            for j in range(0, width):\n",
        "                if img_hist[i][j] < avg_point:\n",
        "                    LS_img[i][j] = int(((img_hist[i][j] - min_P) * ((255 - min_P) / (avg_point - min_P)) + min_P))\n",
        "                    US_img[i][j] = 0\n",
        "                else:\n",
        "                    LS_img[i][j] = 255\n",
        "                    US_img[i][j] = int(((img_hist[i][j] - avg_point) * ((255) / (max_P - avg_point))))\n",
        "\n",
        "        LSR_img.append(LS_img)\n",
        "        USR_img.append(US_img)\n",
        "\n",
        "    LS = np.array(np.dstack(LSR_img), dtype=np.uint8)\n",
        "    US = np.array(np.dstack(USR_img), dtype=np.uint8)\n",
        "\n",
        "    return LS, US\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGsOVwtV76ep"
      },
      "outputs": [],
      "source": [
        "def enhanced_image(img1, img2):\n",
        "\n",
        "    #integration of dual intensity images to get Enhanced-constrast output image\n",
        "    b1,g1,r1 = cv.split(img1)\n",
        "    b2,g2,r2 = cv.split(img2)\n",
        "\n",
        "    height, width = img1.shape[:2]\n",
        "    dual_img=np.zeros((height, width,3),dtype=np.uint8)\n",
        "\n",
        "    dual_img[:,:,0] = np.array(np.add(b1/2, b2/2),dtype = np.uint8)\n",
        "    dual_img[:,:,1] = np.array(np.add(g1/2, g2/2),dtype = np.uint8)\n",
        "    dual_img[:,:,2] = np.array(np.add(r1/2, r2/2),dtype = np.uint8)\n",
        "\n",
        "    return dual_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bToyKrHr794k"
      },
      "outputs": [],
      "source": [
        "#particle class\n",
        "class Particle:\n",
        "  def __init__(self, func, dim, vmin, vmax, seed):\n",
        "    self.rnd = np.random.seed(seed)\n",
        "\n",
        "    # initialize position, velocity, local_best_particle of the particle with 0.0 value\n",
        "    self.velocity = np.zeros(dim)\n",
        "    self.best_part_pos = np.zeros(dim)\n",
        "\n",
        "    self.position = np.random.uniform(vmin, vmax, dim)\n",
        "\n",
        "    # compute fitness of particle\n",
        "    self.fitness = func(self.position) # curr fitness\n",
        "\n",
        "    # initialize best position and fitness of this particle\n",
        "    self.best_part_pos = np.copy(self.position)\n",
        "    self.best_part_fitness = self.fitness     # best fitness\n",
        "\n",
        "\n",
        "def pso(func, max_iter, num_particles, dim, vmin, vmax, params):\n",
        "\n",
        "  # hyper parameters\n",
        "  wmax = params[\"wmax\"]    # maximum inertia\n",
        "  wmin = params[\"wmin\"]    #minimum inertia\n",
        "  c1 = params[\"c1\"] \t   # cognitive (particle)\n",
        "  c2 = params[\"c2\"]       # social (swarm)\n",
        "\n",
        "  rnd = np.random.seed()\n",
        "\n",
        "  # create num_particles\n",
        "  swarm = [Particle(func, dim, vmin, vmax, i) for i in range(num_particles)]\n",
        "\n",
        "  # compute the value of best_position and best_fitness in swarm\n",
        "  best_swarm_pos = np.zeros(dim)\n",
        "  best_swarm_fitness = np.inf # swarm best\n",
        "\n",
        "  # computer best particle of swarm and it's fitness\n",
        "  for i in range(num_particles): # check each particle\n",
        "    if swarm[i].fitness < best_swarm_fitness:\n",
        "      best_swarm_fitness = swarm[i].fitness\n",
        "      best_swarm_pos = np.copy(swarm[i].position)\n",
        "\n",
        "  # main loop of pso\n",
        "  it = 0\n",
        "  while it < max_iter:\n",
        "\n",
        "    # For every 5 iterations print iteration number and best fitness value\n",
        "    if it % 5 == 0:\n",
        "      print(\"Iteration = \" + str(it) + \" best fitness = %f\" % best_swarm_fitness)\n",
        "\n",
        "    w = wmax - ((wmax - wmin)/max_iter)*it\n",
        "\n",
        "    for i in range(num_particles):\n",
        "\n",
        "      # compute new velocity of current particle\n",
        "      swarm[i].velocity = (\n",
        "                           (w * swarm[i].velocity) +\n",
        "                           (c1 * np.random.rand(dim) * (swarm[i].best_part_pos - swarm[i].position)) +\n",
        "                           (c2 * np.random.rand(dim) * (best_swarm_pos -swarm[i].position))\n",
        "                         )\n",
        "\n",
        "      # compute new position using new velocity\n",
        "      for k in range(dim):\n",
        "        swarm[i].position[k] += swarm[i].velocity[k]\n",
        "        swarm[i].position[k] = np.maximum(swarm[i].position[k], vmin)\n",
        "        swarm[i].position[k] = np.minimum(swarm[i].position[k], vmax)\n",
        "\n",
        "      # compute fitness of new position\n",
        "      swarm[i].fitness = func(swarm[i].position)\n",
        "\n",
        "      # check for local best particle\n",
        "      if swarm[i].fitness < swarm[i].best_part_fitness:\n",
        "        swarm[i].best_part_fitness = swarm[i].fitness\n",
        "        swarm[i].best_part_pos = np.copy(swarm[i].position)\n",
        "\n",
        "      # check for global best particle\n",
        "      if swarm[i].fitness < best_swarm_fitness:\n",
        "        best_swarm_fitness = swarm[i].fitness\n",
        "        best_swarm_pos = np.copy(swarm[i].position)\n",
        "\n",
        "    it += 1\n",
        "\n",
        "  gbest ={}\n",
        "  gbest[\"position\"] = best_swarm_pos\n",
        "  gbest[\"cost\"] = best_swarm_fitness\n",
        "\n",
        "  return gbest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxqQKair8FJJ"
      },
      "outputs": [],
      "source": [
        "def pso_image(img):\n",
        "\n",
        "    group = superior_inferior_split(img)\n",
        "\n",
        "    maxi = np.mean(group[\"Pmax\"][0])\n",
        "    inte = np.mean(group[\"Pint\"][0])\n",
        "    mini = np.mean(group[\"Pmin\"][0])\n",
        "\n",
        "    # Defining hyperparameters\n",
        "    n = 50  # number of particles\n",
        "    params = {\"wmax\" : 0.9, \"wmin\" : 0.4, \"c1\" : 2 , \"c2\" : 2}\n",
        "    max_iteration = 100\n",
        "\n",
        "    x = np.array([inte, mini])\n",
        "\n",
        "    def func(X,P_sup = maxi):\n",
        "        return np.square(P_sup - X[0])+np.square(P_sup - X[1])\n",
        "\n",
        "    nVar= 2  # number of variables to optimize\n",
        "    VarMin = 0  # lower bound of variables , you can use np.array() for different variables\n",
        "    VarMax = 255   # upper bound of variables, you can use np.array() for different variables\n",
        "\n",
        "    gbest = pso(func, max_iter=max_iteration, num_particles = n, dim = 2, vmin = VarMin, vmax = VarMax, params = params)\n",
        "\n",
        "    #gamma correction for inferior color channels\n",
        "    mean_colors = gbest['position']\n",
        "    gamma = np.log(mean_colors/255)/np.log(x/255)\n",
        "\n",
        "    group[\"Pint\"][0] = np.array(255*np.power(group[\"Pint\"][0]/255 , gamma[0]))\n",
        "    group[\"Pmin\"][0] = np.array(255*np.power(group[\"Pmin\"][0]/255 , gamma[1]))\n",
        "\n",
        "\n",
        "    pso_res = image(group.values())\n",
        "\n",
        "    return pso_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9nYMdq18KDK"
      },
      "outputs": [],
      "source": [
        "def unsharp_masking(img):\n",
        "\n",
        "    alpha = 0.2\n",
        "    beta = 1 -alpha\n",
        "    img_blur = cv.GaussianBlur(img, (1,1),sigmaX=1)\n",
        "    unsharp_img = cv.addWeighted(img, alpha, img_blur, beta, 0.0)\n",
        "\n",
        "    return unsharp_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocUCY0FsdRuO"
      },
      "outputs": [],
      "source": [
        "def NUCE(img):\n",
        "    neu_img = neutralize_image(img)\n",
        "\n",
        "    #Dual-intensity images fusion based on\n",
        "    #average of mean and median values\n",
        "    img1, img2 = Stretching(neu_img)\n",
        "\n",
        "    dual_img = enhanced_image(img1, img2)\n",
        "\n",
        "    #Swarm-intelligence based mean equalization\n",
        "    pso_res = pso_image(dual_img)\n",
        "\n",
        "    #Unsharp masking (Gaussian blur)\n",
        "    nuce_img = unsharp_masking(pso_res)\n",
        "\n",
        "    return nuce_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXPfEALc8QfB"
      },
      "outputs": [],
      "source": [
        "dir_path = '/content/drive/MyDrive/UGP_EE492A/PSO_results/images/'\n",
        "output_path =  '/content/drive/MyDrive/UGP_EE492A/PSO_results/results/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sazHCIY-8kMG"
      },
      "outputs": [],
      "source": [
        "original_images =[]\n",
        "NUCE_images =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGaIZHSp8nRp"
      },
      "outputs": [],
      "source": [
        "for im in os.listdir(dir_path):\n",
        "\n",
        "  img = cv.imread(dir_path+im,1)\n",
        "  original_images.append(img)\n",
        "\n",
        "  nuce_img = NUCE(img)\n",
        "  NUCE_images.append(nuce_img)\n",
        "\n",
        "  # Save the output image to the output folder\n",
        "  output_image_path = os.path.join(output_path, im)\n",
        "  # cv.imwrite(output_image_path, nuce_img)\n",
        "\n",
        "  # cv.imwrite(\"./results/\"+im.split('/')[-1], nuce_img)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}